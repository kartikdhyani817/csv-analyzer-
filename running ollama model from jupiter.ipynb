{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e0d2c4-2232-49a1-9850-dfb7066e65e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you! I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but rather a computer program designed to simulate conversation and answer questions to the best of my ability based on my training data.\n",
      "\n",
      "I'm here to help with any questions or topics you'd like to discuss. I can provide information on a wide range of subjects, from science and history to entertainment and culture. I can also engage in creative activities like writing stories or generating ideas for art projects.\n",
      "\n",
      "What brings you to this chat? Do you have a specific topic in mind that you'd like to talk about, or are you just looking for some general conversation?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "try:\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": \"Hello, who are you?\"}])\n",
    "    print(response['message']['content'])\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cdeea-01ce-4a06-bd34-cf725162dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ollama serve # run this in terminal "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
